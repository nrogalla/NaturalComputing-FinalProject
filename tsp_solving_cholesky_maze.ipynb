{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNltqeqc6ujA"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SupNRfPjTmnx",
        "outputId": "5924cdaa-da6e-4227-960f-dfe4d223a626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tsplib95\n",
            "  Downloading tsplib95-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from tsplib95) (8.1.7)\n",
            "Collecting Deprecated~=1.2.9 (from tsplib95)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting networkx~=2.1 (from tsplib95)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate~=0.8.7 (from tsplib95)\n",
            "  Downloading tabulate-0.8.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated~=1.2.9->tsplib95) (1.14.1)\n",
            "Installing collected packages: tabulate, networkx, Deprecated, tsplib95\n",
            "  Attempting uninstall: tabulate\n",
            "    Found existing installation: tabulate 0.9.0\n",
            "    Uninstalling tabulate-0.9.0:\n",
            "      Successfully uninstalled tabulate-0.9.0\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.0+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.0+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "bigframes 1.8.0 requires tabulate>=0.9, but you have tabulate 0.8.10 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Deprecated-1.2.14 networkx-2.8.8 tabulate-0.8.10 tsplib95-0.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "303IjQvZGOjF"
      },
      "source": [
        "# Cholesky Maze"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Y0gITdFVSm"
      },
      "outputs": [],
      "source": [
        "from cholesky_maze import *\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD7bHWBVa7CE"
      },
      "source": [
        "### Different Parameter Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWXJdkh3a_20"
      },
      "outputs": [],
      "source": [
        "# Define the parameter sets\n",
        "decay_rates = [0.001, 0.01, 0.1, 'auto']\n",
        "ks = [0.01, 0.05, 0.1, 0.5]\n",
        "ms = [1, 2, 3, 4]\n",
        "epsilons = [1e-10, 1e-8, 1e-6]\n",
        "\n",
        "# Run the simulation with different parameter values\n",
        "datasets = ['ulysses22', 'st70', 'ch150']\n",
        "for dataset in datasets:\n",
        "  for _ in range(10):\n",
        "    for decay_rate in decay_rates:\n",
        "        if decay_rate == 'auto':\n",
        "            decay_rate = 1 / len(load_coordinates(f'{dataset}.tsp'))**2\n",
        "        print(f\"Running simulation with decay_rate={decay_rate}, k={fixed_k}, m={fixed_m}, epsilon={fixed_epsilon}\")\n",
        "        run_simulation(dataset, decay_rate, fixed_k, fixed_m, fixed_epsilon)\n",
        "    for k in ks:\n",
        "        print(f\"Running simulation with decay_rate={fixed_decay_rate}, k={k}, m={fixed_m}, epsilon={fixed_epsilon}\")\n",
        "        run_simulation(dataset, fixed_decay_rate, k, fixed_m, fixed_epsilon)\n",
        "    for m in ms:\n",
        "        print(f\"Running simulation with decay_rate={fixed_decay_rate}, k={fixed_k}, m={m}, epsilon={fixed_epsilon}\")\n",
        "        run_simulation(dataset, fixed_decay_rate, fixed_k, m, fixed_epsilon)\n",
        "    for epsilon in epsilons:\n",
        "        print(f\"Running simulation with decay_rate={fixed_decay_rate}, k={fixed_k}, m={fixed_m}, epsilon={epsilon}\")\n",
        "        run_simulation(dataset, fixed_decay_rate, fixed_k, fixed_m, epsilon)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOHf1gf7JvMX"
      },
      "source": [
        "These were the ones we found to be the most effective:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqYF1d0zJya7"
      },
      "outputs": [],
      "source": [
        "# Fixed parameters\n",
        "fixed_decay_rate = 0.01\n",
        "fixed_k = 0.1\n",
        "fixed_m = 2\n",
        "fixed_epsilon = 1e-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drGe0rHKFnnK"
      },
      "source": [
        "# Repeat runs to account for noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWLIrnhKqTK3"
      },
      "outputs": [],
      "source": [
        "# Run simulation for each dataset and noise factor\n",
        "datasets = ['ulysses22', 'st70', 'ch150']\n",
        "noise_factor = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "dataframes = []\n",
        "\n",
        "for dataset in datasets:\n",
        "    fitnesses = []\n",
        "    fitnesses2 = []\n",
        "    durations = []\n",
        "    durations2 = []\n",
        "    memories = []\n",
        "    memories2 = []\n",
        "    for _ in range(10):\n",
        "      fitness, duration, memory = run_simulation(dataset, noise_factor, func_type='type_i')  # For Type I function\n",
        "      fitness2, duration2, memory2 = run_simulation(dataset, noise_factor, func_type='type_ii', midpoint=0.5, steepness=5)  # For Type II function\n",
        "      fitnesses.append(fitness)\n",
        "      durations.append(duration)\n",
        "      memories.append(memory)\n",
        "\n",
        "      fitnesses2.append(fitness2)\n",
        "      durations2.append(duration2)\n",
        "      memories2.append(memory2)\n",
        "\n",
        "    avg_dist = np.mean(fitnesses)\n",
        "    avg_duration = np.mean(durations)\n",
        "    avg_memory = np.mean(memories)\n",
        "\n",
        "    sd_dist = np.std(fitnesses)\n",
        "    sd_duration = np.std(durations)\n",
        "    sd_memory = np.std(memories)\n",
        "\n",
        "\n",
        "    # Create a DataFrame\n",
        "    data = {\n",
        "        'Algorithm': ['Physarum'],\n",
        "        'Average Distance': [avg_dist],\n",
        "        \"SD Distance\": [sd_dist],\n",
        "        'Average Duration (s)': [avg_duration],\n",
        "        \"SD Duration\": [sd_duration],\n",
        "        'Average Allocated Memory (MB)': [avg_memory],\n",
        "        \"SD Memory\": [sd_memory]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    print(df)\n",
        "\n",
        "    dataframes.append(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alaunRwXJ6Fj"
      },
      "source": [
        "This is the best noise factor that we found."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWuiVqJjJ1Ws"
      },
      "outputs": [],
      "source": [
        "noise_factor = 50"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1N0-kX5KYza"
      },
      "source": [
        "Repeat the runs one last time, with all the correct parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOte0H1eSYe4"
      },
      "outputs": [],
      "source": [
        "# Run simulation for each dataset and noise factor\n",
        "datasets = ['st70', 'ulysses22', 'ch150']\n",
        "\n",
        "dataframes = []\n",
        "\n",
        "for dataset in datasets:\n",
        "    fitnesses = []\n",
        "    durations = []\n",
        "    memories = []\n",
        "    for _ in range(10):\n",
        "      fitness, duration, memory = run_simulation(dataset, noise_factor)\n",
        "      fitnesses.append(fitness)\n",
        "      durations.append(duration)\n",
        "      memories.append(memory)\n",
        "    avg_dist = np.mean(fitnesses)\n",
        "    avg_duration = np.mean(durations)\n",
        "    avg_memory = np.mean(memories)\n",
        "\n",
        "    sd_dist = np.std(fitnesses)\n",
        "    sd_duration = np.std(durations)\n",
        "    sd_memory = np.std(memories)\n",
        "\n",
        "\n",
        "    # Create a DataFrame\n",
        "    data = {\n",
        "        'Algorithm': ['Physarum'],\n",
        "        'Average Distance': [avg_dist],\n",
        "        \"SD Distance\": [sd_dist],\n",
        "        'Average Duration (s)': [avg_duration],\n",
        "        \"SD Duration\": [sd_duration],\n",
        "        'Average Allocated Memory (MB)': [avg_memory],\n",
        "        \"SD Memory\": [sd_memory]\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    dataframes.append(df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
